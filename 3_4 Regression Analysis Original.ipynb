{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64aede63",
   "metadata": {},
   "source": [
    "# REGRESSION ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb508256",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9963122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed05ce0",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba78467",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO']\n",
    "\n",
    "df_dict_state = {state:pd.read_csv('data_preparation_csv\\%s.csv'%state, parse_dates = ['date']).set_index(['date'], drop = True) for state in states}\n",
    "\n",
    "cluster_state = pd.Series({'AC': 1,\n",
    " 'AL': 0,\n",
    " 'AM': 1,\n",
    " 'AP': 1,\n",
    " 'BA': 0,\n",
    " 'CE': 0,\n",
    " 'DF': 0,\n",
    " 'ES': 0,\n",
    " 'GO': 0,\n",
    " 'MA': 1,\n",
    " 'MG': 0,\n",
    " 'MS': 2,\n",
    " 'MT': 0,\n",
    " 'PA': 1,\n",
    " 'PB': 0,\n",
    " 'PE': 0,\n",
    " 'PI': 0,\n",
    " 'PR': 0,\n",
    " 'RJ': 0,\n",
    " 'RN': 0,\n",
    " 'RO': 0,\n",
    " 'RR': 1,\n",
    " 'RS': 0,\n",
    " 'SC': 0,\n",
    " 'SE': 0,\n",
    " 'SP': 2,\n",
    " 'TO': 0}) #a14 24/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb28db",
   "metadata": {},
   "source": [
    "### SHIFT LAG FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86beb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(lag):\n",
    "    for i,state in enumerate(states):\n",
    "        iteration = df_dict_state[state][var_y + var_X + ['cluster']].copy().reset_index()\n",
    "        iteration[var_X] = iteration[var_X].shift(lag)\n",
    "        iteration['state'] = state\n",
    "        iteration = iteration[iteration.date >= (pd.to_datetime('2021-01-16')) + pd.to_timedelta(lag,unit='D')]\n",
    "        if i == 0:\n",
    "            data = iteration\n",
    "        else:\n",
    "            data = pd.concat([data,iteration], ignore_index = True)\n",
    "\n",
    "\n",
    "    for col in google_var:\n",
    "        abs_max = np.abs(data[col]).max()\n",
    "        data[col] = data[col] / abs_max\n",
    "\n",
    "    for col in var_X:\n",
    "        data[col] = 2 * ((data[col] - data[col].min())/(data[col].max() - data[col].min())) - 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc1ba1",
   "metadata": {},
   "source": [
    "### INDENPENDENT VARIABLES CORRELATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e29b73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_X = ['stringency_index_mm14',\n",
    "       'retail_and_recreation_mm14', 'grocery_and_pharmacy_mm14',\n",
    "       'parks_mm14', 'workplaces_mm14',\n",
    "       'residential_mm14', 'hdi', 'demographic_density', 'doses_100k_mm14','cob_vacinal']\n",
    "\n",
    "google_var = ['retail_and_recreation_mm14', 'grocery_and_pharmacy_mm14',\n",
    "       'parks_mm14', 'workplaces_mm14',\n",
    "       'residential_mm14']\n",
    "\n",
    "for i,state in enumerate(states):\n",
    "    iteration = df_dict_state[state].reset_index()\n",
    "    iteration = iteration[iteration.date >= pd.to_datetime('2021-01-16')]\n",
    "    if i == 0:\n",
    "        data = iteration\n",
    "    else:\n",
    "        data = pd.concat([data,iteration], ignore_index = True)\n",
    "\n",
    "correl = data[var_X].corr()\n",
    "sns.heatmap(correl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba41645",
   "metadata": {},
   "source": [
    "### DEFINE DEPENDENT VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_y = ['deaths_100k_mm14']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e901217",
   "metadata": {},
   "source": [
    "### LAG ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf0834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lag_scores = list()\n",
    "for lag in tqdm(range(100)):\n",
    "    for i,state in enumerate(states):\n",
    "        iteration = df_dict_state[state][var_y + var_X + ['cluster']].copy().reset_index()\n",
    "        iteration['state'] = state\n",
    "        iteration[var_X] = iteration[var_X].shift(lag)\n",
    "        iteration = iteration[iteration.date >= (pd.to_datetime('2021-01-16')) + pd.to_timedelta(lag,unit='D')]\n",
    "        \n",
    "        if i == 0:\n",
    "            data = iteration\n",
    "        else:\n",
    "            data = pd.concat([data,iteration], ignore_index = True)\n",
    "            \n",
    "    data[var_X] = 2 * (data[var_X] - data[var_X].min())/(data[var_X].max() - data[var_X].min()) - 1\n",
    "            \n",
    "    X = data[var_X]\n",
    "    y = data[var_y]\n",
    "    \n",
    "    est = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "    \n",
    "    lag_scores.append(est.bic)\n",
    "        \n",
    "\n",
    "plt.plot(range(100),lag_scores)\n",
    "plt.title('BIC X Lag')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a25c8",
   "metadata": {},
   "source": [
    "### LAG DEFINTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = np.argmax(lag_scores)\n",
    "lag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7983d1",
   "metadata": {},
   "source": [
    "### BACKWISE FEATURE SELECTION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwiseselection(X,y,selected_variables = X.columns,alfa = 0.05):\n",
    "    #never fill selected_variables argument, it is used for recursion only#\n",
    "    est = sm.OLS(y, sm.add_constant(X[selected_variables])).fit()\n",
    "    p_values = est.pvalues.drop('const')\n",
    "    if len(p_values[p_values < alfa]) == len(selected_variables):\n",
    "        return selected_variables\n",
    "    else:\n",
    "        selected = selected_variables.drop(est.pvalues.drop('const').idxmax())\n",
    "        return backwiseselection(X,y,selected,alfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e4a45",
   "metadata": {},
   "source": [
    "### SELECTING VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f8762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = shift(lag)[var_X]\n",
    "y = shift(lag)[var_y]\n",
    "\n",
    "for alfa in [0.001,0.01,0.05,0.1,1]:\n",
    "    print(\"\\n for alfa = %.3f, the eliminated features are: \\n\"%alfa)\n",
    "    for feature in var_X:\n",
    "        if feature not in backwiseselection(X,y,alfa = alfa):\n",
    "            print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc0d5b",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION WITH SELECTED VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbe7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs = {cluster : pd.DataFrame(columns = ['LB','Betha','UB'], index = ['const'] + var_X, data = 0) for cluster in ['all',0,1,2]}\n",
    "\n",
    "selected_X = X[backwiseselection(X,y,alfa = 0.05)]\n",
    "\n",
    "est = sm.OLS(y, sm.add_constant(selected_X)).fit()\n",
    "\n",
    "coefs['all'].loc[np.concatenate((['const'],np.array(selected_X.columns))),'Betha'] = est.params\n",
    "coefs['all'].loc[np.concatenate((['const'],np.array(selected_X.columns))),'LB'] = est.conf_int(alpha = 0.05)[0]\n",
    "coefs['all'].loc[np.concatenate((['const'],np.array(selected_X.columns))),'UB'] = est.conf_int(alpha = 0.05)[1]\n",
    "coefs['all'].fillna(0,inplace=True)\n",
    "   \n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a484a8",
   "metadata": {},
   "source": [
    "###  LINEAR REGRESSION WITH SELECTED VARIABLES VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x_i in enumerate(selected_X):\n",
    "   plt.scatter(X[x_i],y)\n",
    "   x_data = np.linspace(-1,1,2)\n",
    "   plt.plot(x_data, est.params[i+1]*x_data + est.params[0], color = 'red')\n",
    "   plt.title(var_y[0] + ' X %s, coef = %.4f'%(x_i,est.params[i+1]))\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1d631",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION WITH CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabc865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ests = list()\n",
    "for k in cluster_state.unique():\n",
    "    \n",
    "    data = shift(lag)\n",
    "    X = data[data['cluster']==k][var_X]\n",
    "    y = data[data['cluster']==k][var_y]\n",
    "\n",
    "    print('\\n for cluster \\n', k)\n",
    "\n",
    "    \n",
    "    \n",
    "    X_variables = backwiseselection(X,y,alfa = 0.05)\n",
    "\n",
    "    selected_X = X[X_variables]\n",
    "    y = y[var_y]\n",
    "    \n",
    "    print(\"removed variables for cluster k are:\")\n",
    "    for feature in var_X:\n",
    "        if feature not in X_variables:\n",
    "            print(feature)\n",
    "\n",
    "\n",
    "    \n",
    "    est = sm.OLS(y, sm.add_constant(selected_X)).fit()\n",
    "    ests.append(est)\n",
    "    \n",
    "    \n",
    "    coefs[k].loc[np.concatenate((['const'],np.array(X_variables))),'Betha'] = est.params\n",
    "    coefs[k].loc[np.concatenate((['const'],np.array(X_variables))),'LB'] = est.conf_int(alpha = 0.05)[0]\n",
    "    coefs[k].loc[np.concatenate((['const'],np.array(X_variables))),'UB'] = est.conf_int(alpha = 0.05)[1]\n",
    "    coefs[k].fillna(0,inplace=True)\n",
    "\n",
    "    print(est.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016dc67",
   "metadata": {},
   "source": [
    "###  LINEAR REGRESSION WITH SELECTED VARIABLES VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce888532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sse_all_vector = []\n",
    "sse_cluster_vector = []\n",
    "ratio_vector = []\n",
    "\n",
    "for state in states:\n",
    "    k = cluster_state[state]\n",
    "    real_curve = data[data['state'] == state].set_index('date',drop=True)[var_y]\n",
    "    parameters_values = data[data['state'] == state].set_index('date',drop=True)[var_X]\n",
    "    estimated_curve_all = (coefs['all']['Betha'][1:] * parameters_values[var_X]).sum(axis=1) + coefs['all'].loc['const','Betha']\n",
    "    estimated_curve_cluster = (coefs[k]['Betha'][1:] * parameters_values[var_X]).sum(axis=1) + coefs[k].loc['const','Betha']\n",
    "    \n",
    "    \n",
    "    SSE_all = mean_squared_error(estimated_curve_all,real_curve)\n",
    "    SSE_cluster = mean_squared_error(estimated_curve_cluster,real_curve)\n",
    "    ratio = -100 * ((SSE_cluster/ SSE_all) - 1)\n",
    "    \n",
    "    sse_all_vector.append(SSE_all)\n",
    "    sse_cluster_vector.append(SSE_cluster)\n",
    "    ratio_vector.append(ratio)\n",
    "\n",
    "    # Just a figure and one subplot\n",
    "    f, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "    ax.set_title(state + \" belonging to cluster %s\"%k)\n",
    "    ax.plot(real_curve, label=\"original y\")\n",
    "    ax.plot(estimated_curve_all, label=\"y_hat no cluster\")\n",
    "    ax.plot(estimated_curve_cluster, label=\"y_hat with cluster, SSE_improv = %.3f\"%ratio)\n",
    "    ax.legend()\n",
    "    plt.savefig(\"graf_final%s.png\"%state)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b889fb",
   "metadata": {},
   "source": [
    "### BETAS PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(columns = ['variable','estimated \\u03B2','cluster'])\n",
    "\n",
    "for k in coefs:\n",
    "    iteration = coefs[k].reset_index().rename({'index':'variable'},axis=1)\n",
    "    iteration = pd.concat([iteration[[\"variable\",\"UB\"]].rename({\"UB\":\"estimated \\u03B2\"},axis=1),iteration[[\"variable\",\"LB\"]].rename({\"LB\":\"estimated \\u03B2\"},axis=1)])\n",
    "    iteration[\"cluster\"] = k\n",
    "    a = pd.concat([a,iteration])\n",
    "a = a.reset_index(drop=True)\n",
    "\n",
    "fig = plt.subplots(figsize=(15,12),dpi=350)\n",
    "sns.set_theme(style=\"white\")\n",
    "ax = sns.pointplot(x=\"estimated \\u03B2\",y=\"variable\",data=a,join = False,\n",
    "                   hue = 'cluster',errwidth=0.8,capsize=0.2, dodge = 0.8)\n",
    "\n",
    "for i in range(4):\n",
    "    points = ax.collections[i]\n",
    "    size = points.get_sizes().item()\n",
    "    new_sizes = [size * 0.1 for name in ax.get_yticklabels()]\n",
    "    points.set_sizes(new_sizes)\n",
    "for i in range(12):\n",
    "    ax.axhline((i-1/2),linewidth=0.5, color = 'grey')\n",
    "ax.axvline(0,linewidth=0.5,color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ac13f",
   "metadata": {},
   "source": [
    "### EXPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206393f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SSE Analysis\n",
    "sse_all_vector.append(np.mean(sse_all_vector))\n",
    "sse_cluster_vector.append(np.mean(sse_cluster_vector))\n",
    "ratio_vector.append(np.mean(ratio_vector))\n",
    "states = [' AC ', ' AL ', ' AM ', ' AP ', ' BA ', ' CE ', ' DF ', ' ES ', ' GO ', ' MA ', ' MG ', ' MS ', ' MT ', ' PA ', ' PB ', ' PE ', ' PI ', ' PR ', ' RJ ', ' RN ', ' RO ', ' RR ', ' RS ', ' SC ', ' SE ', ' SP ', ' TO ','MEAN']\n",
    "\n",
    "\n",
    "## SSE Analysis 01\n",
    "sse_all = pd.DataFrame(sse_all_vector).rename(columns = {0:'sse_all'})\n",
    "sse_cluster = pd.DataFrame(sse_cluster_vector).rename(columns = {0:'sse_cluster'})\n",
    "ratio = pd.DataFrame(ratio_vector).rename(columns = {0:'ratio'})\n",
    "states = pd.DataFrame(states).rename(columns = {0:'state'})\n",
    "\n",
    "sse_analysis = states.join(sse_all)\n",
    "sse_analysis = sse_analysis.join(sse_cluster)\n",
    "sse_analysis = sse_analysis.join(ratio)\n",
    "sse_analysis.to_csv('sse_analysis.csv')\n",
    "\n",
    "\n",
    "## SSE Analysis 02\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
